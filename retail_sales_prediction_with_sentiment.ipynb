{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bffa017",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from math import sqrt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional, Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a7a4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "df = pd.read_csv('retail_sales_dataset.csv')\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df = df.sort_values('Date')\n",
    "df.set_index('Date', inplace=True)\n",
    "target_variable = 'Total Amount'\n",
    "\n",
    "# Generate synthetic sentiment\n",
    "def generate_review(row):\n",
    "    if row['Total Amount'] > 1000:\n",
    "        return f\"I loved this {row['Product Category']} purchase! Great quality!\"\n",
    "    elif row['Total Amount'] > 500:\n",
    "        return f\"Pretty good {row['Product Category']} item.\"\n",
    "    else:\n",
    "        return f\"Disappointing {row['Product Category']} experience.\"\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "df['Review'] = df.apply(generate_review, axis=1)\n",
    "df['Sentiment'] = df['Review'].apply(lambda x: sid.polarity_scores(x)['compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe91dfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "train_size = int(len(df) * 0.8)\n",
    "train = df.iloc[:train_size]\n",
    "test = df.iloc[train_size:]\n",
    "\n",
    "# Data Scaling\n",
    "scaler_no_sent = MinMaxScaler()\n",
    "scaler_with_sent = MinMaxScaler()\n",
    "train_scaled_no_sent = scaler_no_sent.fit_transform(train[[target_variable]])\n",
    "test_scaled_no_sent = scaler_no_sent.transform(test[[target_variable]])\n",
    "train_scaled_with_sent = scaler_with_sent.fit_transform(train[[target_variable, 'Sentiment']])\n",
    "test_scaled_with_sent = scaler_with_sent.transform(test[[target_variable, 'Sentiment']])\n",
    "\n",
    "# Sequence creation for LSTM\n",
    "def create_sequences(data, seq_length):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i + seq_length])\n",
    "        y.append(data[i + seq_length, 0])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "seq_length = 14\n",
    "X_train_no_sent, y_train_no_sent = create_sequences(train_scaled_no_sent, seq_length)\n",
    "X_test_no_sent, y_test_no_sent = create_sequences(test_scaled_no_sent, seq_length)\n",
    "X_train_with_sent, y_train_with_sent = create_sequences(train_scaled_with_sent, seq_length)\n",
    "X_test_with_sent, y_test_with_sent = create_sequences(test_scaled_with_sent, seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c177de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improved LSTM model\n",
    "def build_improved_lstm_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Bidirectional(LSTM(32)))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "# Train LSTM models with early stopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "lstm_no_sent = build_improved_lstm_model((seq_length, 1))\n",
    "lstm_no_sent.fit(X_train_no_sent, y_train_no_sent, validation_split=0.2,\n",
    "                 epochs=50, batch_size=32, callbacks=[early_stop], verbose=1)\n",
    "lstm_pred_no_sent_scaled = lstm_no_sent.predict(X_test_no_sent, verbose=0)\n",
    "\n",
    "lstm_with_sent = build_improved_lstm_model((seq_length, 2))\n",
    "lstm_with_sent.fit(X_train_with_sent, y_train_with_sent, validation_split=0.2,\n",
    "                   epochs=50, batch_size=32, callbacks=[early_stop], verbose=1)\n",
    "lstm_pred_with_sent_scaled = lstm_with_sent.predict(X_test_with_sent, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597c8886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescale predictions and targets for LSTM\n",
    "lstm_pred_no_sent = scaler_no_sent.inverse_transform(lstm_pred_no_sent_scaled)\n",
    "y_test_no_sent_rescaled = scaler_no_sent.inverse_transform(y_test_no_sent.reshape(-1, 1))\n",
    "\n",
    "dummy_sentiment = np.zeros_like(lstm_pred_with_sent_scaled)\n",
    "lstm_pred_with_sent = scaler_with_sent.inverse_transform(\n",
    "    np.concatenate((lstm_pred_with_sent_scaled, dummy_sentiment), axis=1)\n",
    ")[:, 0].reshape(-1, 1)\n",
    "\n",
    "y_test_with_sent_rescaled = scaler_with_sent.inverse_transform(\n",
    "    np.concatenate((y_test_with_sent.reshape(-1, 1), dummy_sentiment), axis=1)\n",
    ")[:, 0].reshape(-1, 1)\n",
    "\n",
    "# Trim test sets for LSTM alignment\n",
    "adjusted_test_no_sent = test.iloc[seq_length:]\n",
    "adjusted_test_with_sent = test.iloc[seq_length:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cdff0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Random Forest data\n",
    "def prepare_rf_data(df, include_sentiment=False):\n",
    "    df_rf = df.copy()\n",
    "    df_rf['Day'] = df_rf.index.day\n",
    "    df_rf['Month'] = df_rf.index.month\n",
    "    df_rf['Weekday'] = df_rf.index.weekday\n",
    "    df_rf = pd.get_dummies(df_rf, columns=['Gender', 'Product Category'])\n",
    "    y = df_rf[target_variable]\n",
    "    drop_cols = ['Transaction ID', 'Customer ID', 'Review', target_variable]\n",
    "    if not include_sentiment:\n",
    "        drop_cols.append('Sentiment')\n",
    "    X = df_rf.drop(columns=drop_cols)\n",
    "    return X, y\n",
    "\n",
    "X_train_rf_no_sent, y_train_rf_no_sent = prepare_rf_data(train, include_sentiment=False)\n",
    "X_test_rf_no_sent, y_test_rf_no_sent = prepare_rf_data(test, include_sentiment=False)\n",
    "X_test_rf_no_sent = X_test_rf_no_sent.reindex(columns=X_train_rf_no_sent.columns, fill_value=0)\n",
    "\n",
    "rf_no_sent = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_no_sent.fit(X_train_rf_no_sent, y_train_rf_no_sent)\n",
    "rf_pred_no_sent = rf_no_sent.predict(X_test_rf_no_sent)\n",
    "\n",
    "X_train_rf_with_sent, y_train_rf_with_sent = prepare_rf_data(train, include_sentiment=True)\n",
    "X_test_rf_with_sent, y_test_rf_with_sent = prepare_rf_data(test, include_sentiment=True)\n",
    "X_test_rf_with_sent = X_test_rf_with_sent.reindex(columns=X_train_rf_with_sent.columns, fill_value=0)\n",
    "\n",
    "rf_with_sent = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_with_sent.fit(X_train_rf_with_sent, y_train_rf_with_sent)\n",
    "rf_pred_with_sent = rf_with_sent.predict(X_test_rf_with_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef16ead1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARIMA models\n",
    "sales_daily = df[[target_variable, 'Sentiment']].resample('D').agg({target_variable: 'sum', 'Sentiment': 'mean'})\n",
    "sales_daily['Sentiment'] = sales_daily['Sentiment'].fillna(0)\n",
    "train_size_arima = int(len(sales_daily) * 0.8)\n",
    "train_arima = sales_daily.iloc[:train_size_arima]\n",
    "test_arima = sales_daily.iloc[train_size_arima:]\n",
    "\n",
    "arima_no_sent = ARIMA(train_arima[target_variable], order=(5, 1, 0))\n",
    "arima_no_sent_fit = arima_no_sent.fit()\n",
    "arima_pred_no_sent = arima_no_sent_fit.forecast(steps=len(test_arima))\n",
    "\n",
    "arima_with_sent = ARIMA(train_arima[target_variable], order=(5, 1, 0), exog=train_arima['Sentiment'])\n",
    "arima_with_sent_fit = arima_with_sent.fit()\n",
    "arima_pred_with_sent = arima_with_sent_fit.forecast(steps=len(test_arima), exog=test_arima['Sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d97b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "def evaluate_model(name, y_true, y_pred):\n",
    "    print(f\"{name}:\")\n",
    "    print(\"  RMSE:\", round(sqrt(mean_squared_error(y_true, y_pred)), 2))\n",
    "    print(\"  MAE :\", round(mean_absolute_error(y_true, y_pred), 2))\n",
    "    print(\"  R²  :\", round(r2_score(y_true, y_pred), 2))\n",
    "    print()\n",
    "\n",
    "print(\"\\n✅ Final Model Evaluation\\n\")\n",
    "evaluate_model(\"LSTM (No Sentiment)\", adjusted_test_no_sent[[target_variable]].values, lstm_pred_no_sent)\n",
    "evaluate_model(\"LSTM (With Sentiment)\", adjusted_test_with_sent[[target_variable]].values, lstm_pred_with_sent)\n",
    "evaluate_model(\"Random Forest (No Sentiment)\", y_test_rf_no_sent, rf_pred_no_sent)\n",
    "evaluate_model(\"Random Forest (With Sentiment)\", y_test_rf_with_sent, rf_pred_with_sent)\n",
    "evaluate_model(\"ARIMA (No Sentiment)\", test_arima[target_variable].values, arima_pred_no_sent)\n",
    "evaluate_model(\"ARIMA (With Sentiment)\", test_arima[target_variable].values, arima_pred_with_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302e9486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ARIMA predictions\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(test_arima.index, test_arima[target_variable], label='Actual Sales')\n",
    "plt.plot(test_arima.index, arima_pred_no_sent, label='ARIMA No Sentiment')\n",
    "plt.plot(test_arima.index, arima_pred_with_sent, label='ARIMA With Sentiment')\n",
    "plt.title('ARIMA Prediction vs Actual')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
